{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "\n",
    "> This script compute dimensionality reduction of Simulation Dataset. Input data must be of shape **<[n_simulation, n_timesteps,3, n_nodes]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "from argparse import ArgumentParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from dyna_PCA.get_matrix import get_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "parser = ArgumentParser(description=\"Principal Components Analisys\")\n",
    "parser.add_argument(\"--file\", \n",
    "                    type= str,\n",
    "                    help=\"Path to file containing data\")\n",
    "parser.add_argument(\"--n_comp\", \n",
    "                    type= float,\n",
    "                    default='0.9',\n",
    "                    help=\"Number of components [int] or amount variance in percentage (ex. 0.9 for 90% )\")\n",
    "parser.add_argument(\"--Std\", \n",
    "                    type=bool,\n",
    "                    default= True,\n",
    "                    help=\"Standardize with Sklearn standard scaler\")\n",
    "\n",
    "class PrincipalComponentsAnalysis():\n",
    "\n",
    "    def __init__(self, file,  n_comp, std):\n",
    "\n",
    "        self.random_seed = 42\n",
    "        self.file = file\n",
    "        self.n_components = n_comp\n",
    "        self.std = std\n",
    "    \n",
    "    def read_file(self):\n",
    "        assert os.path.exists(self.file), \"File not found\"          \n",
    "        self.sim = np.load(self.file)\n",
    "        self.n_sim = self.sim.shape[0]\n",
    "        self.timesteps = self.sim.shape[1]\n",
    "        self.n_nodes = self.sim.shape[3]\n",
    "        assert self.sim.shape[2] == 3, \"Simulation data must be of shape [n_simulation, n_timesteps,3, n_nodes]\"\n",
    "        \n",
    "    def train_split(self):\n",
    "        self.index = np.array(range(0,self.n_sim))\n",
    "        assert len(self.index) == self.n_sim \n",
    "        self.train, self.valid, self.train_idx, self.valid_idx = train_test_split(self.sim, self.index,  test_size=0.2 , shuffle=True , random_state=self.random_seed) \n",
    "            \n",
    "    def get_matrix(self):\n",
    "        self.train_mat = get_matrix(self.train)\n",
    "        self.test_mat= get_matrix(self.valid)\n",
    "    \n",
    "    def p_c(self):\n",
    "        scaler = StandardScaler(with_mean=True, with_std=True) \n",
    "        scaler_std = scaler.fit(self.train_mat)\n",
    "        y_Data_std = scaler_std.transform(self.train_mat)\n",
    "\n",
    "        var = PCA().fit(y_Data_std).explained_variance_\n",
    "        cumulative_variance = np.cumsum(PCA().fit(y_Data_std).explained_variance_ratio_)\n",
    "\n",
    "        pca = PCA(n_components = self.n_components)\n",
    "        y_PCA = pca.fit_transform(pd.DataFrame(y_Data_std))\n",
    "        n_comps = pca.n_components_\n",
    "\n",
    "        # MSE to for Pc error\n",
    "        y_PCA_inverse = pca.inverse_transform(y_PCA) # Inverse transfrom of sample data as per PCs to original form\n",
    "        y_PCA_InvTrans_Data = scaler_std.inverse_transform(y_PCA_inverse, copy=None) # inverse standardization\n",
    "        pca_mse = mean_squared_error(self.train_mat,y_PCA_InvTrans_Data)\n",
    "        pca_mae = mean_absolute_error(self.train_mat,y_PCA_InvTrans_Data)\n",
    "        print(\"MSE: {} for {} components:\".format(pca_mse, n_comps))\n",
    "        print(\"MAE: {} for {} components:\".format(pca_mae, n_comps))\n",
    "        reshape_y_pca2 =[]\n",
    "        pd.DataFrame(reshape_y_pca2)\n",
    "        for i in range(0,len(self.train_idx)):\n",
    "            temp_1 = y_PCA[(i*(self.timesteps-1)+i):(i*(self.timesteps-1)+i+self.timesteps)].T\n",
    "            temp_2 = temp_1.flatten()\n",
    "            temp = pd.DataFrame(temp_2)\n",
    "            reshape_y_pca2.append(temp.T)\n",
    "\n",
    "        np.row_stack(reshape_y_pca2)   \n",
    "        y_PCA_ReSh = pd.DataFrame(np.row_stack(reshape_y_pca2), index = self.train_idx) \n",
    "        y_train =y_PCA   \n",
    "\n",
    "    def get_principal_components(self):\n",
    "        self.read_file()\n",
    "        self.train_split()\n",
    "        self.get_matrix()\n",
    "        self.p_c()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "#|export\n",
    "if __name__ == \"__main__\":\n",
    "    args= parser.parse_args()\n",
    "    print(\"Path to data file\", args.file)\n",
    "    print(\"Number of components [int] or amount variance in percentage [float]: \", args.n_comp)\n",
    "    print(\"Standardization of dataset\", args.std)\n",
    "    obj= PrincipalComponentsAnalysis(args.file, args.n_comp, args.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008300001280836246 for n_comps: 244\n",
      "MAE: 0.0726128701510692 for n_comps: 244\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "obj= PrincipalComponentsAnalysis(\"../test_data/node_displacement.npy\", 0.9, True)\n",
    "obj.get_principal_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
